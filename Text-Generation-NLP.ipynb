{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nimport tensorflow\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense , Flatten ,Embedding,Input,LSTM, BatchNormalization, Dropout, InputLayer, ReLU\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2023-01-07T22:31:14.405639Z","iopub.execute_input":"2023-01-07T22:31:14.406077Z","iopub.status.idle":"2023-01-07T22:31:14.414047Z","shell.execute_reply.started":"2023-01-07T22:31:14.406042Z","shell.execute_reply":"2023-01-07T22:31:14.412914Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"file = open(\"/kaggle/input/data-for-text-generation-nlp/GOT_TextData.txt\", 'r')\ndata = file.read()\nfile.close()\ndata[0:1000]","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:14.531167Z","iopub.execute_input":"2023-01-07T22:31:14.531559Z","iopub.status.idle":"2023-01-07T22:31:14.552678Z","shell.execute_reply.started":"2023-01-07T22:31:14.531527Z","shell.execute_reply":"2023-01-07T22:31:14.551881Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'A Game Of Thrones \\nBook One of A Song of Ice and Fire \\nBy George R. R. Martin \\nPROLOGUE \\n\"We should start back,\" Gared urged as the woods began to grow dark around them. \"The wildlings are \\ndead.\" \\n\"Do the dead frighten you?\" Ser Waymar Royce asked with just the hint of a smile. \\nGared did not rise to the bait. He was an old man, past fifty, and he had seen the lordlings come and go. \\n\"Dead is dead,\" he said. \"We have no business with the dead.\" \\n\"Are they dead?\" Royce asked softly. \"What proof have we?\" \\n\"Will saw them,\" Gared said. \"If he says they are dead, that\\'s proof enough for me.\" \\nWill had known they would drag him into the quarrel sooner or later. He wished it had been later rather \\nthan sooner. \"My mother told me that dead men sing no songs,\" he put in. \\n\"My wet nurse said the same thing, Will,\" Royce replied. \"Never believe anything you hear at a woman\\'s \\ntit. There are things to be learned even from the dead.\" His voice echoed, too loud in the twilit forest. \\nPage 1\\n\\n\"We h'"},"metadata":{}}]},{"cell_type":"code","source":"def text_cleaning(text):\n    temp = text\n    temp = re.sub(\"[%s]\" % re.escape(string.punctuation),'',temp)\n    temp = [word for word in temp.split() if word.isalpha()]\n    temp = [word.lower() for word in temp]\n    text = \" \".join(temp)\n    return text\n\ndata = text_cleaning(data)\ndata = data[0:750000]\ndata[0:1000]","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:14.610896Z","iopub.execute_input":"2023-01-07T22:31:14.611521Z","iopub.status.idle":"2023-01-07T22:31:14.777179Z","shell.execute_reply.started":"2023-01-07T22:31:14.611485Z","shell.execute_reply":"2023-01-07T22:31:14.776334Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'a game of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of a smile gared did not rise to the bait he was an old man past fifty and he had seen the lordlings come and go dead is dead he said we have no business with the dead are they dead royce asked softly what proof have we will saw them gared said if he says they are dead thats proof enough for me will had known they would drag him into the quarrel sooner or later he wished it had been later rather than sooner my mother told me that dead men sing no songs he put in my wet nurse said the same thing will royce replied never believe anything you hear at a womans tit there are things to be learned even from the dead his voice echoed too loud in the twilit forest page we have a long ride before us gared pointed out eight days maybe nine and night i'"},"metadata":{}}]},{"cell_type":"code","source":"no_of_words = len(data.split())\nprint(\"Total number of words in the text = \", no_of_words)\n\nno_of_vocab_words = len(set(data.split()))\nprint(\"Total number of words in the vocabulary of text = \", no_of_vocab_words)\n\nprint(\"Percentage of vocabulary words = \", (no_of_vocab_words*100)/no_of_words,\"%\")","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:14.779227Z","iopub.execute_input":"2023-01-07T22:31:14.779578Z","iopub.status.idle":"2023-01-07T22:31:14.822578Z","shell.execute_reply.started":"2023-01-07T22:31:14.779547Z","shell.execute_reply":"2023-01-07T22:31:14.821278Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Total number of words in the text =  145099\nTotal number of words in the vocabulary of text =  8779\nPercentage of vocabulary words =  6.050351828751404 %\n","output_type":"stream"}]},{"cell_type":"code","source":"text_sequences = []\nseq_length = 51\ntext_list = data.split()\n\nfor i in range(0,len(text_list)-seq_length+1):\n    temp = text_list[i:i+seq_length]\n    temp = \" \".join(temp)\n    text_sequences.append(temp)\n    \nlen(text_sequences[-1].split())","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:14.824163Z","iopub.execute_input":"2023-01-07T22:31:14.824512Z","iopub.status.idle":"2023-01-07T22:31:15.138172Z","shell.execute_reply.started":"2023-01-07T22:31:14.824481Z","shell.execute_reply":"2023-01-07T22:31:15.137066Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"51"},"metadata":{}}]},{"cell_type":"code","source":"text_sequences[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:15.140119Z","iopub.execute_input":"2023-01-07T22:31:15.140468Z","iopub.status.idle":"2023-01-07T22:31:15.148109Z","shell.execute_reply.started":"2023-01-07T22:31:15.140439Z","shell.execute_reply":"2023-01-07T22:31:15.146755Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"['a game of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint',\n 'game of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of',\n 'of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of a',\n 'thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of a smile',\n 'book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of a smile gared']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(text_sequences)\nsequences = tokenizer.texts_to_sequences(text_sequences)\nvocab_size = len(tokenizer.word_index)+1\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:15.149660Z","iopub.execute_input":"2023-01-07T22:31:15.150003Z","iopub.status.idle":"2023-01-07T22:31:26.778556Z","shell.execute_reply.started":"2023-01-07T22:31:15.149975Z","shell.execute_reply":"2023-01-07T22:31:26.777018Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"8780"},"metadata":{}}]},{"cell_type":"code","source":"import pickle\npickle.dump(tokenizer, open('tokenizer_text_generation.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:26.780286Z","iopub.execute_input":"2023-01-07T22:31:26.781003Z","iopub.status.idle":"2023-01-07T22:31:26.795854Z","shell.execute_reply.started":"2023-01-07T22:31:26.780957Z","shell.execute_reply":"2023-01-07T22:31:26.795013Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"sequences = np.array(sequences)\nX, y = sequences[:,:-1], sequences[:,-1] \ny = to_categorical(y, num_classes=vocab_size)\nseq_length = X.shape[1]\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:26.797209Z","iopub.execute_input":"2023-01-07T22:31:26.798455Z","iopub.status.idle":"2023-01-07T22:31:27.993369Z","shell.execute_reply.started":"2023-01-07T22:31:26.798410Z","shell.execute_reply":"2023-01-07T22:31:27.992098Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"((145049, 50), (145049, 8780))"},"metadata":{}}]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, seq_length, input_length=seq_length ))\nmodel.add(LSTM(100, return_sequences=True))\nmodel.add(LSTM(100))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(vocab_size, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')\ncheckpoint = tensorflow.keras.callbacks.ModelCheckpoint(\"text_generation_model.h5\",moniter='loss',save_best_only=True,mode='min')\nRLR = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='loss',patience=2,factor=0.001,min_delta=0.01)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:27.996507Z","iopub.execute_input":"2023-01-07T22:31:27.997538Z","iopub.status.idle":"2023-01-07T22:31:28.625233Z","shell.execute_reply.started":"2023-01-07T22:31:27.997501Z","shell.execute_reply":"2023-01-07T22:31:28.624001Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 50, 50)            439000    \n_________________________________________________________________\nlstm (LSTM)                  (None, 50, 100)           60400     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 100)               80400     \n_________________________________________________________________\ndense (Dense)                (None, 100)               10100     \n_________________________________________________________________\ndense_1 (Dense)              (None, 8780)              886780    \n=================================================================\nTotal params: 1,476,680\nTrainable params: 1,476,680\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X,y,batch_size=128, epochs=100, callbacks=[checkpoint,RLR])","metadata":{"execution":{"iopub.status.busy":"2023-01-07T20:36:08.744028Z","iopub.execute_input":"2023-01-07T20:36:08.744471Z","iopub.status.idle":"2023-01-07T20:57:54.959768Z","shell.execute_reply.started":"2023-01-07T20:36:08.744436Z","shell.execute_reply":"2023-01-07T20:57:54.958915Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Epoch 1/100\n1134/1134 [==============================] - 15s 11ms/step - loss: 6.6279\nEpoch 2/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 6.2149\nEpoch 3/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 5.9993\nEpoch 4/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.8264\nEpoch 5/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.7004\nEpoch 6/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.5669\nEpoch 7/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.4382\nEpoch 8/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.3177\nEpoch 9/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.2079\nEpoch 10/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.1073\nEpoch 11/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 5.0141\nEpoch 12/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.9254\nEpoch 13/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.8427\nEpoch 14/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.7636\nEpoch 15/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 4.6882\nEpoch 16/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.6171\nEpoch 17/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 4.5497\nEpoch 18/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.4851\nEpoch 19/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.4266\nEpoch 20/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.3694\nEpoch 21/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.3148\nEpoch 22/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 4.2637\nEpoch 23/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.2151\nEpoch 24/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 4.1690\nEpoch 25/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.1265\nEpoch 26/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.0830\nEpoch 27/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 4.0408\nEpoch 28/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 4.0007\nEpoch 29/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.9630\nEpoch 30/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.9252\nEpoch 31/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.8892\nEpoch 32/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.8547\nEpoch 33/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.8190\nEpoch 34/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.7832\nEpoch 35/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.7515\nEpoch 36/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.7178\nEpoch 37/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.6879\nEpoch 38/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.6561\nEpoch 39/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.6243\nEpoch 40/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.5949\nEpoch 41/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.5633\nEpoch 42/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.5351\nEpoch 43/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.5054\nEpoch 44/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.4785\nEpoch 45/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.4492\nEpoch 46/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.4235\nEpoch 47/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.3949\nEpoch 48/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.3686\nEpoch 49/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.3422\nEpoch 50/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.3164\nEpoch 51/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.2906\nEpoch 52/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.2653\nEpoch 53/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.2418\nEpoch 54/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.2160\nEpoch 55/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.1931\nEpoch 56/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 3.1699\nEpoch 57/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.1438\nEpoch 58/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.1192\nEpoch 59/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.0983\nEpoch 60/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.0719\nEpoch 61/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.0518\nEpoch 62/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.0305\nEpoch 63/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 3.0076\nEpoch 64/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.9854\nEpoch 65/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.9632\nEpoch 66/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.9420\nEpoch 67/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.9211\nEpoch 68/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.9009\nEpoch 69/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.8792\nEpoch 70/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.8609\nEpoch 71/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.8407\nEpoch 72/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.8168\nEpoch 73/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.8008\nEpoch 74/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.7824\nEpoch 75/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.7604\nEpoch 76/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.7421\nEpoch 77/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.7280\nEpoch 78/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.7070\nEpoch 79/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.6876\nEpoch 80/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.6693\nEpoch 81/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.6528\nEpoch 82/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.6369\nEpoch 83/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.6175\nEpoch 84/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.6013\nEpoch 85/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.5837\nEpoch 86/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.5720\nEpoch 87/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.5502\nEpoch 88/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.5356\nEpoch 89/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.5220\nEpoch 90/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.5015\nEpoch 91/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.4893\nEpoch 92/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.4752\nEpoch 93/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.4601\nEpoch 94/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.4414\nEpoch 95/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.4321\nEpoch 96/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.4135\nEpoch 97/100\n1134/1134 [==============================] - 13s 12ms/step - loss: 2.3990\nEpoch 98/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.3868\nEpoch 99/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.3720\nEpoch 100/100\n1134/1134 [==============================] - 13s 11ms/step - loss: 2.3577\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('text_generation_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def produce_output_text(model, tokenizer, seq_length, seed_text, n_words):\n    final_words = list()\n    in_text = seed_text\n    for i in range(n_words):\n        encoded = tokenizer.texts_to_sequences([in_text])[0]\n        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n        yhat = model.predict(encoded, verbose=0)\n        yhat = np.argmax(yhat,axis=1)\n        out_word = ''\n        \n        for word, index in tokenizer.word_index.items():\n            if index==yhat:\n                out_word = word\n                break\n        \n        in_text = in_text + ' ' + out_word\n        \n        final_words.append(out_word)\n    \n    return \" \".join(final_words)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T21:03:10.699896Z","iopub.execute_input":"2023-01-07T21:03:10.700250Z","iopub.status.idle":"2023-01-07T21:03:10.707537Z","shell.execute_reply.started":"2023-01-07T21:03:10.700220Z","shell.execute_reply":"2023-01-07T21:03:10.706349Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"seed_text = text_sequences[np.random.randint(0,len(text_sequences))]\nprint( seed_text + '\\n' )\nproduce_output_text(model, tokenizer, seq_length, seed_text, n_words=50)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T21:03:10.887180Z","iopub.execute_input":"2023-01-07T21:03:10.887733Z","iopub.status.idle":"2023-01-07T21:03:12.615616Z","shell.execute_reply.started":"2023-01-07T21:03:10.887696Z","shell.execute_reply":"2023-01-07T21:03:12.614709Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have\n\n","output_type":"stream"},{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"'you seen a real hand and a candle to kings landing to the realm and without the dragon the first man remained to ben my lord the baby dreams of the lannisters he told you all i command whisperers i have to go quiet as a second to put it'"},"metadata":{}}]},{"cell_type":"code","source":"seed_text = text_sequences[np.random.randint(0,len(text_sequences))]\nprint( seed_text + '\\n' )\nproduce_output_text(model, tokenizer, seq_length, seed_text, n_words=75)","metadata":{"execution":{"iopub.status.busy":"2023-01-07T21:03:39.227523Z","iopub.execute_input":"2023-01-07T21:03:39.227894Z","iopub.status.idle":"2023-01-07T21:03:41.800835Z","shell.execute_reply.started":"2023-01-07T21:03:39.227864Z","shell.execute_reply":"2023-01-07T21:03:41.799834Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"the imp will no doubt swear the blade was lost or stolen while he was at winterfell and with his hireling dead who is there to give him the lie he tossed the knife lightly to ned my counsel is to drop that in the river and forget that it was\n\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"'not a man who suits to believe that you are fresher he did not ask me theres a lie ned said hotly you had the king and i did not ask the beast raged or eunuchs it is wrong to ask that you were going to listen the old man replied isnt why i shall be a man grown she said with a sudden affirmation of his head grenn sit at the door toward the'"},"metadata":{}}]},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:31:28.626796Z","iopub.execute_input":"2023-01-07T22:31:28.627993Z","iopub.status.idle":"2023-01-07T22:31:28.636533Z","shell.execute_reply.started":"2023-01-07T22:31:28.627941Z","shell.execute_reply":"2023-01-07T22:31:28.635212Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'a game of thrones book one of a song of ice and fire by george r r martin prologue we should start back gared urged as the woods began to grow dark around them the wildlings are dead do the dead frighten you ser waymar royce asked with just the hint of a smile gared did not rise to the bait he was an old man past fifty and he had seen the lordlings come and go dead is dead he said we have no business with the dead are they dead royce asked softly what proof have we will saw them gared said if he says they are dead thats proof enough for me will had known they would drag him into the quarrel sooner or later he wished it had been later rather than sooner my mother told me that dead men sing no songs he put in my wet nurse said the same thing will royce replied never believe anything you hear at a womans tit there are things to be learned even from the dead his voice echoed too loud in the twilit forest page we have a long ride before us gared pointed out eight days maybe nine and night i'"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://stackabuse.com/gpt-style-text-generation-in-python-with-tensorflowkeras/","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Using GPT","metadata":{}},{"cell_type":"code","source":"#get transformers\nfrom transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n#get large GPT2 tokenizer and GPT2 model\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\nGPT2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)\n#view model parameters\nGPT2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:10:39.898267Z","iopub.execute_input":"2023-01-07T22:10:39.898767Z","iopub.status.idle":"2023-01-07T22:11:03.737646Z","shell.execute_reply.started":"2023-01-07T22:10:39.898719Z","shell.execute_reply":"2023-01-07T22:11:03.736400Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n\nAll the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-large.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tfgp_t2lm_head_model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ntransformer (TFGPT2MainLayer multiple                  774030080 \n=================================================================\nTotal params: 774,030,080\nTrainable params: 774,030,080\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have\"\ninput_text","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:16:06.175470Z","iopub.execute_input":"2023-01-07T22:16:06.176134Z","iopub.status.idle":"2023-01-07T22:16:06.181918Z","shell.execute_reply.started":"2023-01-07T22:16:06.176097Z","shell.execute_reply":"2023-01-07T22:16:06.180996Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have'"},"metadata":{}}]},{"cell_type":"code","source":"# encode context the generation is conditioned on\ninput_ids = tokenizer.encode(input_text, return_tensors='tf')\n\n# # generate text until the output length (which includes the context length) reaches 50\n# greedy_output = GPT2.generate(input_ids, max_length = 100)\n\n# print(\"Output:\\n\" + 100 * '-')\n# print(tokenizer.decode(greedy_output[0], skip_special_tokens = True))","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:20:23.800901Z","iopub.execute_input":"2023-01-07T22:20:23.801235Z","iopub.status.idle":"2023-01-07T22:20:23.808216Z","shell.execute_reply.started":"2023-01-07T22:20:23.801205Z","shell.execute_reply":"2023-01-07T22:20:23.806920Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Top-K and Top-P Sampling\n\n#combine both sampling techniques\nsample_outputs = GPT2.generate(\n                              input_ids,\n                              do_sample = True, \n                              max_length = 2*100,                              #to test how long we can generate and it be coherent\n                              #temperature = .7,\n                              top_k = 50, \n                              top_p = 0.85, \n                              num_return_sequences = 5\n)\n\nprint(\"Output:\\n\" + 100 * '-')\nfor i, sample_output in enumerate(sample_outputs):\n    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n    print('')","metadata":{"execution":{"iopub.status.busy":"2023-01-07T22:17:25.930660Z","iopub.execute_input":"2023-01-07T22:17:25.931410Z","iopub.status.idle":"2023-01-07T22:20:23.798898Z","shell.execute_reply.started":"2023-01-07T22:17:25.931358Z","shell.execute_reply":"2023-01-07T22:20:23.797517Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Output:\n----------------------------------------------------------------------------------------------------\n0: a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have you seen this guy? he stood still with his arms crossed he saw pyp jon said pyp. he has a big fat face and jon had never seen such a pretty face before. jon started to get worried pyp was coming in. the two stared at each other. pyp's eyes flashed with a dark purple light and he was in front of them. the fat face looked at him with big teeth jon was afraid to touch pyp or to see his face pyp was smiling and laughing as jon was getting ready to run out jon grabbed the door hanger and began to push it open. he felt like he was gonna explode in a million pieces. pyp was in front...\n\n1: a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have a seat pyp sat on the seat jon leaned back pyp took a seat beside page the round fat face sighed jon asked if you want to talk about how bad the weather is pyp answered that it's going to get worse then why do we have to do anything the round fat face growled pyp went back inside and the round fat face made a sound as if it was in pain and a sickly voice went out saying \"no pyp what's wrong you have to leave now\" the round fat face sat in its chair and turned back to pyp \"you can't leave now you have to wait for the rest of us and when we get back you'll have to wait for a while\"...\n\n2: a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have to have my pappy make it look like I gave my pappy the go ahead to leave he said yes i guess we'll leave page my pappy is an idiot not a single word can he tell us what the truth is if my pappy tells us the truth i'm telling you now jon says you're fucking stupid why don't you go back home page pyp was a lot more polite than he seemed he was right not saying much if i was pyp it would probably mean death if i was pyp it would probably mean death too but i am not a bad person it's just my personality and you will always be a person who makes a lot of people upset, I'm not that stupid you know...\n\n3: a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have a drink I'll have some if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink page I'll have one if you'll have one too I'll have a drink...\n\n4: a feeble shake of his head too scared even to talk a burst of laughter filled the hall jon heard pyp squeaking in a high voice he stood lets go outside page the round fat face looked up at him suspicious why what will we do outside talk jon said have to leave him alone pyp and his friends left and jon came back in pyp looked at jon and he smiled and said hey why are you smiling I'm not sorry jon then said you got me a new shirt pyp said you should call me pyp and his friends then left jon came back in and pyp stood hes holding a cigarette and he said look at this pyp said look at this pyp and his friends left jon came back in and pyp stood hes holding a cigarette and he said look at this pyp and his friends left jon came back in and pyp stood hes holding a cigarette and he said look at this pyp and his friends left jon came back...\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}